{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1PPe_WY2LJI3tve_BXVm40igiVG9dj3FU","timestamp":1727221542702}],"gpuType":"A100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Instruction Finetuning\n"],"metadata":{"id":"nODwmF0MEOQb"}},{"cell_type":"markdown","source":[],"metadata":{"id":"A-JSVT_ortrN"}},{"cell_type":"markdown","source":["### 데이터셋 구축\n","\n","1. 목적 정의: 먼저, 세부 튜닝을 통해 달성하고자 하는 목표를 명확히 합니다.\n","1. 데이터 수집: 목표에 맞는 데이터를 수집합니다. 이 데이터는 공개 데이터셋일 수도 있고, 사용자가 직접 수집한 데이터일 수도 있습니다.\n","\n","1. 데이터 가공: 수집한 데이터를 모델 훈련에 적합하게 가공합니다. 이 과정에서는 데이터를 정제하고, 필요한 형식으로 변환하는 작업이 포함됩니다."],"metadata":{"id":"0BGrlf29Eowf"}},{"cell_type":"markdown","source":["### 공개 데이터셋 다운로드"],"metadata":{"id":"H9r0smmEIAjT"}},{"cell_type":"code","source":["!pip install -U datasets==2.17.0"],"metadata":{"id":"ilVIo8M0IE1e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset, DatasetDict, concatenate_datasets\n","\n","def format_instruction01(example):\n","    text = f\"\"\"<start_of_turn>user\\n{example[\"instruction\"]}<end_of_turn><start_of_turn>model\\n{example[\"en_instruction\"]}<end_of_turn>\"\"\"\n","    # # 추가 컨텍스트(input 필드)가 있는 경우\n","    # if example['input'] and len(example['input']) > 0:\n","    #     text = f\"\"\"<bos><start_of_turn>user\\n{example[\"instruction\"]}\\n{example[\"input\"]}<end_of_turn><start_of_turn>model\\n{example[\"en_instruction\"]}<eos>\"\"\"\n","    # # input 필드가 없는 경우\n","    # # else:\n","    #     text = f\"\"\"<bos><start_of_turn>user\\n{example[\"instruction\"]}<end_of_turn><start_of_turn>model\\n{example[\"en_instruction\"]}<eos>\"\"\"\n","\n","    return {'prompt': text}\n","\n","def format_instruction02(example):\n","    text = f\"\"\"<start_of_turn>user\\n{example[\"en_instruction\"]}<end_of_turn><start_of_turn>model\\n{example[\"instruction\"]}<end_of_turn>\"\"\"\n","    # # 추가 컨텍스트(input 필드)가 있는 경우\n","    # if example['input'] and len(example['input']) > 0:\n","    #     text = f\"\"\"<bos><start_of_turn>user\\n{example[\"instruction\"]}\\n{example[\"input\"]}<end_of_turn>\\n<start_of_turn>model\\n{example[\"en_instruction\"]}<eos>\"\"\"\n","    # # input 필드가 없는 경우\n","    # # else:\n","    #     text = f\"\"\"<bos><start_of_turn>user\\n{example[\"instruction\"]}<end_of_turn>\\n<start_of_turn>model\\n{example[\"en_instruction\"]}<eos>\"\"\"\n","\n","    return {'prompt': text}\n","\n","_dataset = load_dataset(\"nlp-with-deeplearning/ko.databricks-dolly-15k\")\n","\n","\n","# 데이터셋 로드\n","_dataset = load_dataset(\"nlp-with-deeplearning/ko.databricks-dolly-15k\")\n","dataset = DatasetDict({\"train\": concatenate_datasets([_dataset.map(format_instruction01)[\"train\"], _dataset.map(format_instruction02)[\"train\"]])})\n","\n","# 데이터셋의 구조 확인\n","print(dataset)"],"metadata":{"id":"_Sg9dv0QIWWR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset['train'][0]"],"metadata":{"id":"o1basYqSJFys"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Gemma 데이터셋 포맷팅\n","\n","```<start_of_turn>user```<br>\n","```What is Cramer's Rule?<end_of_turn>```<br>\n","```<start_of_turn>model```<br>\n","```Cramer's Rule is ...<end_of_turn>```"],"metadata":{"id":"aaQbtRTTovBm"}},{"cell_type":"markdown","source":["### 모델 로드 및 튜닝:\n","\n","1. 모델 학습: gemma-2b 모델을 로드하고, 준비된 데이터셋을 사용하여 모델을 세부 튜닝합니다. 이 과정에서는 학습률, 에폭 수 등의 파라미터를 조정할 수 있습니다.\n","1. 평가 및 반복: 튜닝된 모델을 평가하고 결과를 확인합니다. 필요에 따라 여러 번 반복하여 모델의 성능을 최적화할 수 있습니다."],"metadata":{"id":"DtExQUBlEFMv"}},{"cell_type":"code","source":["!pip install -qU transformers==4.38.0 accelerate==0.27.1 bitsandbytes==0.42.0 peft==0.8.2 trl==0.7.10"],"metadata":{"id":"XrefsFXqFM9V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"rd1Ya28FujGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import pandas as pd\n","import numpy as np\n","import warnings\n","import json\n","import time\n","\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    DataCollatorForLanguageModeling,\n","    BitsAndBytesConfig,\n","    TrainingArguments,\n","    pipeline,\n","    logging,\n",")\n","from peft import LoraConfig, get_peft_model, PeftModel, prepare_model_for_kbit_training, TaskType\n","from trl import SFTTrainer\n","\n","from huggingface_hub import notebook_login"],"metadata":{"id":"jRjOEOq9JBju"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["notebook_login()"],"metadata":{"id":"9Cn_f9eewOs0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_id = \"google/gemma-2b\"\n","\n","bnb_config = BitsAndBytesConfig(load_in_4bit=True,\n","                                bnb_4bit_quant_type=\"nf4\",\n","                                bnb_4bit_compute_dtype=torch.bfloat16)\n","\n","\n","model = AutoModelForCausalLM.from_pretrained(model_id,\n","                                             quantization_config=bnb_config,\n","                                             device_map={\"\":0})\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)"],"metadata":{"id":"bZ87WNIPJZLN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"aIaUHTsMmmJ-"}},{"cell_type":"code","source":["tokenizer.pad_token = tokenizer.unk_token"],"metadata":{"id":"bN96zjNf7O25"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.save_pretrained('gemma-tokenizer')\n","model.save_pretrained('gemma-base-model')"],"metadata":{"id":"yzlqhXEASKpG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = dataset.map(lambda samples: tokenizer(samples[\"prompt\"]), batched=True)\n","dataset = dataset['train'].train_test_split(test_size=0.2)"],"metadata":{"id":"SPJn3dPwwBll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = dataset[\"train\"]\n","test_data = dataset[\"test\"]"],"metadata":{"id":"NRAQtIgVxfG6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_data[0])"],"metadata":{"id":"FJLdkGrnxmXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_completion(query: str, model, tokenizer):\n","\n","  prompt_template = f\"\"\"<start_of_turn>user\\n{query}<end_of_turn><start_of_turn>model\"\"\"\n","  prompt = prompt_template.format(query=query)\n","  encodeds = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n","  model_inputs = encodeds.to(\"cuda:0\")\n","  generated_ids = model.generate(**model_inputs, max_new_tokens=256)\n","  decoded = tokenizer.decode(generated_ids[0])\n","  return decoded\n","\n","# Fine tuning 이전\n","result = get_completion(query=\"건강을 유지하기 위한 세 가지 팁을 알려주세요.\", model=model, tokenizer=tokenizer)\n","print(result)\n"],"metadata":{"id":"pO4pjPKdxny-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","\n","lora_config = LoraConfig(\n","    r=4,\n","    lora_alpha=4,\n","    lora_dropout=0.05,\n","    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",")\n","\n","\n","# 양자화된 모델을 학습하기 전, 전처리를 위해 호출\n","model = prepare_model_for_kbit_training(model)\n","model = get_peft_model(model, lora_config)\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=train_data,\n","    eval_dataset=test_data,\n","    dataset_text_field=\"prompt\",\n","    peft_config=lora_config,\n","    args=TrainingArguments(\n","        per_device_train_batch_size=1,\n","        gradient_accumulation_steps=4,\n","        warmup_steps=10,\n","        max_steps=500,\n","        learning_rate=2e-4,\n","        fp16=True,\n","        logging_steps=10,\n","        output_dir=\"outputs\",\n","        optim=\"paged_adamw_8bit\",\n","    ),\n","    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",")\n","\n","trainer.train()"],"metadata":{"id":"NTmSRl0Fz4KY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fine tuning 이후\n","result = get_completion(query=\"건강을 유지하기 위한 세 가지 팁을 알려주세요.\",\n","                        model=trainer.model,\n","                        tokenizer=tokenizer)\n","print(result)"],"metadata":{"id":"OeygbIZg24Y_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fine tuning 이후\n","result = get_completion(query=\"빨강\",\n","                        model=trainer.model,\n","                        tokenizer=tokenizer)\n","print(result)"],"metadata":{"id":"09pIPcLpBuAP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fine tuning 이후\n","result = get_completion(query=\"red\",\n","                        model=trainer.model,\n","                        tokenizer=tokenizer)\n","print(result)"],"metadata":{"id":"sewUkBqe65QY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 모델 저장"],"metadata":{"id":"KH9FFSWS2uue"}},{"cell_type":"code","source":["new_model = \"gemma-2b-translator-lora\"\n","trainer.model.save_pretrained(new_model)"],"metadata":{"id":"lLGaVpqY2n7a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForCausalLM.from_pretrained(model_id)\n","model = PeftModel.from_pretrained(model, new_model)\n","\n","model = model.merge_and_unload()\n","model.save_pretrained('gemma-2b-translator-merged')"],"metadata":{"id":"KISasdAIicD5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\"\n","\n","!pip install -U mediapipe==0.10.15"],"metadata":{"id":"WSqYrJl6Me6i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"ZVgwStbptG6g"}},{"cell_type":"code","source":["from mediapipe.tasks.python.genai import converter"],"metadata":{"id":"iEQbM0wUMqXd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = converter.ConversionConfig(input_ckpt='./gemma-2b-translator-merged', ckpt_format='safetensors', model_type='GEMMA_2B', backend='gpu', output_dir='./tflite', combine_file_only=False, vocab_model_file='./gemma-tokenizer', lora_ckpt='./gemma-2b-translator-lora', lora_rank=4, lora_output_tflite_file='./gemma-2b-translator-lora.bin', output_tflite_file='./gemma-2b-translator-merged.bin');\n","converter.convert_checkpoint(config)"],"metadata":{"id":"bF2-GG_lNEEL"},"execution_count":null,"outputs":[]}]}